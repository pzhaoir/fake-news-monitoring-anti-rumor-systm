{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "E9f_Ov2F_G5W",
    "outputId": "236ca477-0aa7-4981-f803-acdf87a5fb55"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Input, GlobalMaxPooling1D, LSTM\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding, Dropout, Activation, Flatten\n",
    "from keras.models import Model\n",
    "from keras.initializers import Constant\n",
    "from keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from nltk.stem import PorterStemmer \n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import *\n",
    "\n",
    "\n",
    "# Use English stemmer.\n",
    "word_stemmer = PorterStemmer()\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "from gensim.models.keyedvectors import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "zBPa7eAj4F-D",
    "outputId": "db486c0a-f9b3-4209-bee4-112ac81ad3c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras==2.1.5\n",
      "  Downloading Keras-2.1.5-py2.py3-none-any.whl (334 kB)\n",
      "\u001b[K     |████████████████████████████████| 334 kB 2.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.5) (1.18.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.1.5) (3.13)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.5) (1.15.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.5) (1.4.1)\n",
      "Installing collected packages: keras\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: Keras 2.4.3\n",
      "    Uninstalling Keras-2.4.3:\n",
      "      Successfully uninstalled Keras-2.4.3\n",
      "Successfully installed keras-2.1.5\n"
     ]
    }
   ],
   "source": [
    "!pip install keras==2.1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xfo4Qofn_G5c"
   },
   "outputs": [],
   "source": [
    "real_news_df = pd.read_csv('sample_data/8000-1.csv')\n",
    "fake_news_df = pd.read_csv('sample_data/fake_news_dataset_csv.csv', encoding= 'unicode_escape').dropna()\n",
    "#real_news_df = real_news_df.rename(columns={\"headline\": \"Article\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "4j2mwKxs_G5g",
    "outputId": "c66923bc-5034-4d32-e020-37965189d1dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8799, 6)\n",
      "(8810, 6)\n"
     ]
    }
   ],
   "source": [
    "real_news_df['real_fact'] = 1\n",
    "fake_news_df['real_fact'] = 0\n",
    "print(real_news_df.shape)\n",
    "print(fake_news_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VtAXZs2G_G5k"
   },
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kFVwDWE3_G5l"
   },
   "outputs": [],
   "source": [
    "def decontracted(phrase):\n",
    "  # specific\n",
    "  phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
    "  phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "  # general\n",
    "  phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "  phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "  phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "  phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "  phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "  phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "  phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "  phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "  return phrase\n",
    "\n",
    "\n",
    "\n",
    "def get_cleaned_data(input_data, mode='df'):\n",
    "  stop = stopwords.words('english')\n",
    "  \n",
    "  input_df = ''\n",
    "  \n",
    "  if mode != 'df':\n",
    "      input_df = pd.DataFrame([input_data], columns=['Article'])\n",
    "  else:\n",
    "      input_df = input_data\n",
    "      \n",
    "  #lowercase the text\n",
    "  input_df['Article'] = input_df['Article'].str.lower()\n",
    "  \n",
    "  input_df['Article'] = input_df['Article'].apply(lambda elem: decontracted(elem))\n",
    "  \n",
    "  #remove special characters\n",
    "  input_df['Article'] = input_df['Article'].apply(lambda elem: re.sub(r\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", elem))\n",
    "  \n",
    "  # remove numbers\n",
    "  input_df['Article'] = input_df['Article'].apply(lambda elem: re.sub(r\"\\d+\", \"\", elem))\n",
    "  \n",
    "  #remove stopwords\n",
    "  input_df['Article'] = input_df['Article'].apply(lambda x: ' '.join([word.strip() for word in x.split() if word not in (stop)]))\n",
    "  \n",
    "  #stemming, changes the word to root form\n",
    "#     input_df['text'] = input_df['text'].apply(lambda words: [word_stemmer.stem(word) for word in words])\n",
    "  \n",
    "  #lemmatization, same as stemmer, but language corpus is used to fetch the root form, so resulting words make sense\n",
    "#     more description @ https://www.datacamp.com/community/tutorials/stemming-lemmatization-python\n",
    "  input_df['Article'] = input_df['Article'].apply(lambda words: (wordnet_lemmatizer.lemmatize(words)))\n",
    "#     print(input_df.head(3))\n",
    "  \n",
    "  return input_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "194DgDMm_G5o",
    "outputId": "6b2414f8-c668-442b-b7ab-06654a9daf45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
      "(17609, 9)\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "fake_news_df = get_cleaned_data(fake_news_df)\n",
    "real_news_df = get_cleaned_data(real_news_df)\n",
    "news_data_df = pd.concat([real_news_df, fake_news_df], ignore_index = True)\n",
    "print(news_data_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9I2ehPNWZ-CY"
   },
   "outputs": [],
   "source": [
    "news_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s5DMhhaz_G5v"
   },
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 500\n",
    "MAX_NUM_WORDS = 10000\n",
    "EMBEDDING_DIM = 300\n",
    "VALIDATION_SPLIT = 0.2\n",
    "\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(news_data_df.Article,news_data_df.real_fact,random_state = 42, test_size=VALIDATION_SPLIT, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tu0LrqQD_G5y"
   },
   "source": [
    "# Vectorize the text samples into a 2D integer tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Necp3Sum_G5z",
    "outputId": "0d07ac1f-6ba1-427f-fdd7-d0531bcdde32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16951 unique tokens. and 14087 lines \n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "\n",
    "# Transforms each text in texts to a sequence of integers. \n",
    "# So it basically takes each word in the text and replaces it with its corresponding integer value from the word_index dictionary.\n",
    "# sequences = tokenizer.texts_to_sequences(news_data_df.text)\n",
    "tokenized_train = tokenizer.texts_to_sequences(x_train)\n",
    "X_train = pad_sequences(tokenized_train, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found {} unique tokens. and {} lines '.format(len(word_index), len(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "QypEc-0K_aSb",
    "outputId": "fefdd62d-f3a9-4719-87bd-bbe1509ba928"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-09-18 21:07:50--  https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.69.214\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.69.214|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1647046227 (1.5G) [application/x-gzip]\n",
      "Saving to: ‘/root/input/GoogleNews-vectors-negative300.bin.gz’\n",
      "\n",
      "GoogleNews-vectors- 100%[===================>]   1.53G  34.9MB/s    in 46s     \n",
      "\n",
      "2020-09-18 21:08:36 (34.4 MB/s) - ‘/root/input/GoogleNews-vectors-negative300.bin.gz’ saved [1647046227/1647046227]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -P /root/input/ -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "28L7p9e2ARgp"
   },
   "outputs": [],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "hSSC_p3S_G52",
    "outputId": "1c9643dd-e969-431c-8df6-935c4691e725"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:254: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 500000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "tokenized_test = tokenizer.texts_to_sequences(x_test)\n",
    "X_test = pad_sequences(tokenized_test, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "def get_embeddings(path):\n",
    "  # model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300', binary=True, limit=500000)\n",
    "  wv_from_bin = KeyedVectors.load_word2vec_format(path, binary=True, limit=500000) \n",
    "  #extracting word vectors from google news vector\n",
    "  embeddings_index = {}\n",
    "  for word, vector in zip(wv_from_bin.vocab, wv_from_bin.vectors):\n",
    "      coefs = np.asarray(vector, dtype='float32')\n",
    "      embeddings_index[word] = coefs\n",
    "\n",
    "  return embeddings_index\n",
    "\n",
    "embeddings_index = {}\n",
    "embeddings_index = get_embeddings('/root/input/GoogleNews-vectors-negative300.bin.gz')\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VShdUe1m_G56"
   },
   "source": [
    "# Preparing embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E7bcmA6q_G56"
   },
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "embedding_matrix = np.zeros((vocab_size, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    try:\n",
    "        embedding_vector = embeddings_index[word]\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    except KeyError:\n",
    "        embedding_matrix[i]=np.random.normal(0,np.sqrt(0.25),EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CheemUFh_G5-"
   },
   "source": [
    "# LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Kx7sSQe_G5_"
   },
   "outputs": [],
   "source": [
    "def lstm_net1():\n",
    "    model = Sequential()\n",
    "\n",
    "    #Non-trainable embeddidng layer\n",
    "    model.add(Embedding(vocab_size, output_dim=EMBEDDING_DIM, weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH, trainable=False))\n",
    "    \n",
    "    model.add(LSTM(units=128 , return_sequences = True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=64))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(units = 32 , activation = 'relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zj6NdGzk_G6C",
    "outputId": "2ef08e40-fe27-4acd-b955-64928ebeb2ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 500, 300)          5085600   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 500, 128)          219648    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 5,356,769\n",
      "Trainable params: 271,169\n",
      "Non-trainable params: 5,085,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#training an LSTM network\n",
    "model2 = lstm_net1()\n",
    "\n",
    "batch_size = 256\n",
    "epochs = 8\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zKn9a5Sl_G6F",
    "outputId": "0acee09d-82de-4a8e-868f-7d06ec87a05a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "56/56 [==============================] - 465s 8s/step - loss: 0.4641 - accuracy: 0.7728 - val_loss: 0.3340 - val_accuracy: 0.8668\n",
      "Epoch 2/8\n",
      "56/56 [==============================] - 589s 11s/step - loss: 0.3149 - accuracy: 0.8655 - val_loss: 0.2975 - val_accuracy: 0.8739\n",
      "Epoch 3/8\n",
      "56/56 [==============================] - 660s 12s/step - loss: 0.2769 - accuracy: 0.8856 - val_loss: 0.2793 - val_accuracy: 0.8822\n",
      "Epoch 4/8\n",
      "56/56 [==============================] - 720s 13s/step - loss: 0.2474 - accuracy: 0.9006 - val_loss: 0.3022 - val_accuracy: 0.8705\n",
      "Epoch 5/8\n",
      "56/56 [==============================] - 725s 13s/step - loss: 0.2172 - accuracy: 0.9167 - val_loss: 0.2575 - val_accuracy: 0.8986\n",
      "Epoch 6/8\n",
      "56/56 [==============================] - 745s 13s/step - loss: 0.1911 - accuracy: 0.9274 - val_loss: 0.2849 - val_accuracy: 0.8807\n",
      "Epoch 7/8\n",
      "56/56 [==============================] - 758s 14s/step - loss: 0.1902 - accuracy: 0.9280 - val_loss: 0.2441 - val_accuracy: 0.9018\n",
      "Epoch 8/8\n",
      "56/56 [==============================] - 758s 14s/step - loss: 0.1508 - accuracy: 0.9437 - val_loss: 0.2720 - val_accuracy: 0.8927\n"
     ]
    }
   ],
   "source": [
    "history = model2.fit(X_train, y_train, batch_size = batch_size , validation_data = (X_test,y_test) , epochs = epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "07_mwkKb_G6I"
   },
   "source": [
    "# LSTM Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I023VeD7_G6I",
    "outputId": "e863cfa5-9536-444b-bdaa-0a137955ada3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-28-710dadce3f55>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xd05f3c2988>"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred = model2.predict_classes(X_test)\n",
    "cf_matrix = confusion_matrix(y_test,pred)\n",
    "sns.heatmap(cf_matrix, annot=True, fmt='g', xticklabels = ['Fake','Real'] , yticklabels = ['Fake','Real'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-EvsGeQs_G6M",
    "outputId": "1a590bd0-ed89-4d84-d456-825b9e8d0424"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score is  0.8921136521583494\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "auc_score = roc_auc_score(y_test, pred)\n",
    "print(\"AUC score is \", auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dfh8ImM8_G6P",
    "outputId": "933cfdde-a3f0-4465-8f48-7fcb20b7f6f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score is 0.8921484566389025\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "F1_score = f1_score(y_test, pred, average='macro')\n",
    "print(\"F1 score is\", F1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vaWQBKZz_G6S",
    "outputId": "ab370cd1-415e-4540-9ab4-74e677141062"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracy is  0.8926746166950597\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score = accuracy_score(y_test, pred)\n",
    "print(\"Acuracy is \", accuracy_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RugzW2es_G6V"
   },
   "source": [
    "# Use 8800 data as training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BHbwQQEB_G6W",
    "outputId": "37b4fe64-a1fa-4ce0-8431-8c6e4d7f4c68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(type(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FYJagpQt_G6Z"
   },
   "outputs": [],
   "source": [
    "whole_train = news_data_df['Article']\n",
    "whole_train_label = news_data_df['real_fact']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k48PkZcp_G6c",
    "outputId": "12a335c8-071a-4fe8-cb67-22fc805c6480"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18830 unique tokens. and 17609 lines \n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "\n",
    "tokenizer.fit_on_texts(whole_train)\n",
    "\n",
    "# Transforms each text in texts to a sequence of integers. \n",
    "# So it basically takes each word in the text and replaces it with its corresponding integer value from the word_index dictionary.\n",
    "# sequences = tokenizer.texts_to_sequences(news_data_df.text)\n",
    "tokenized_train = tokenizer.texts_to_sequences(whole_train)\n",
    "Whole_train = pad_sequences(tokenized_train, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found {} unique tokens. and {} lines '.format(len(word_index), len(Whole_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UFn_Wyy-_G6f",
    "outputId": "83906e2e-65cb-4cf1-e3b9-0f5a30098d68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "69/69 [==============================] - 792s 11s/step - loss: 0.6196 - accuracy: 0.6888 - val_loss: 0.4311 - val_accuracy: 0.8055\n",
      "Epoch 2/8\n",
      "69/69 [==============================] - 795s 12s/step - loss: 0.4690 - accuracy: 0.7760 - val_loss: 0.5089 - val_accuracy: 0.7516\n",
      "Epoch 3/8\n",
      "69/69 [==============================] - 896s 13s/step - loss: 0.4044 - accuracy: 0.8156 - val_loss: 0.5386 - val_accuracy: 0.7425\n",
      "Epoch 4/8\n",
      "69/69 [==============================] - 1083s 16s/step - loss: 0.3549 - accuracy: 0.8444 - val_loss: 0.5772 - val_accuracy: 0.7323\n",
      "Epoch 5/8\n",
      "69/69 [==============================] - 1290s 19s/step - loss: 0.3018 - accuracy: 0.8709 - val_loss: 0.6659 - val_accuracy: 0.7104\n",
      "Epoch 6/8\n",
      "69/69 [==============================] - 1689s 24s/step - loss: 0.2643 - accuracy: 0.8881 - val_loss: 0.6911 - val_accuracy: 0.7195\n",
      "Epoch 7/8\n",
      "69/69 [==============================] - 905s 13s/step - loss: 0.2299 - accuracy: 0.9060 - val_loss: 0.7589 - val_accuracy: 0.7022\n",
      "Epoch 8/8\n",
      "69/69 [==============================] - 835s 12s/step - loss: 0.1899 - accuracy: 0.9227 - val_loss: 0.8814 - val_accuracy: 0.6817\n"
     ]
    }
   ],
   "source": [
    "history = model2.fit(Whole_train, whole_train_label, batch_size = batch_size , validation_data = (X_test,y_test) , epochs = epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W1yd6QU7_G6i",
    "outputId": "2c1402da-6e42-4436-bd82-a66123c1ac2c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xd059736388>"
      ]
     },
     "execution_count": 39,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred = model2.predict_classes(X_test)\n",
    "cf_matrix = confusion_matrix(y_test,pred)\n",
    "sns.heatmap(cf_matrix, annot=True, fmt='g', xticklabels = ['Fake','Real'] , yticklabels = ['Fake','Real'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "79qwn2OC_G6l",
    "outputId": "4d0389fd-c2f5-45f6-d8e0-552f29f5bbcb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17609,)\n"
     ]
    }
   ],
   "source": [
    "print(whole_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "96-eBGkv_G6p",
    "outputId": "309631c4-5212-4779-eb03-158c6bc59bb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score is  0.6819853492493224\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "auc_score = roc_auc_score(y_test, pred)\n",
    "print(\"AUC score is \", auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bhJxHb99_G6s",
    "outputId": "21cf36df-8b90-4f1d-c8c3-a47de75c98a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score is 0.6815380725051916\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "F1_score = f1_score(y_test, pred, average='macro')\n",
    "print(\"F1 score is\", F1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_hJSwpFQ_G6v",
    "outputId": "95a315a5-8dbc-4107-b0b8-1a7484069e3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracy is  0.6817149346961954\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score = accuracy_score(y_test, pred)\n",
    "print(\"Acuracy is \", accuracy_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8qThWT9NBaeP"
   },
   "source": [
    "# **CNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "domvzc8RBxqK"
   },
   "outputs": [],
   "source": [
    "def cnn_net1():\n",
    "  model = Sequential()\n",
    "\n",
    "  #Non-trainable embeddidng layer\n",
    "  model.add(Embedding(vocab_size, output_dim=EMBEDDING_DIM, weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH, trainable=False))\n",
    "  \n",
    "  model.add(Dropout(0.2))\n",
    "  model.add(Conv1D(filters=128, kernel_size=4, activation='relu'))\n",
    "  model.add(GlobalMaxPooling1D())\n",
    "  model.add(Dropout(0.2))\n",
    "  model.add(Dense(units = 250 , activation = 'relu'))\n",
    "  model.add(Dense(1, activation='sigmoid'))\n",
    "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "  \n",
    "  return model\n",
    "\n",
    "\n",
    "def get_pred_output(text_to_check):\n",
    "  sequences = tokenizer.texts_to_sequences([text_to_check])\n",
    "  data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "  predicted_val = model.predict_classes(data)\n",
    "#     predicted_val = model.predict(data)    \n",
    "#     if predicted_val.max() > 0.7:\n",
    "#         output = 1\n",
    "#     else:\n",
    "#         output = 0\n",
    "  return predicted_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "NkZC1MHJB_sH",
    "outputId": "ea7d4980-30a1-4d8d-d31a-1fb7486a03c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 500, 300)          5085600   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 500, 300)          0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 497, 128)          153728    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 250)               32250     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 251       \n",
      "=================================================================\n",
      "Total params: 5,271,829\n",
      "Trainable params: 186,229\n",
      "Non-trainable params: 5,085,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# train a 1D convnet with global maxpooling\n",
    "model_1 = cnn_net1()\n",
    "\n",
    "batch_size = 256\n",
    "epochs = 8\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "Bq5-oS5f_G6y",
    "outputId": "ff376804-7ca2-4ef9-d5e3-acd0d58dfa28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "56/56 [==============================] - 105s 2s/step - loss: 0.5246 - accuracy: 0.7420 - val_loss: 0.3759 - val_accuracy: 0.8277\n",
      "Epoch 2/8\n",
      "56/56 [==============================] - 105s 2s/step - loss: 0.3483 - accuracy: 0.8477 - val_loss: 0.3336 - val_accuracy: 0.8569\n",
      "Epoch 3/8\n",
      "56/56 [==============================] - 105s 2s/step - loss: 0.2965 - accuracy: 0.8752 - val_loss: 0.2814 - val_accuracy: 0.8805\n",
      "Epoch 4/8\n",
      "56/56 [==============================] - 105s 2s/step - loss: 0.2374 - accuracy: 0.9010 - val_loss: 0.2842 - val_accuracy: 0.8816\n",
      "Epoch 5/8\n",
      "56/56 [==============================] - 108s 2s/step - loss: 0.2173 - accuracy: 0.9129 - val_loss: 0.2471 - val_accuracy: 0.9020\n",
      "Epoch 6/8\n",
      "56/56 [==============================] - 105s 2s/step - loss: 0.1841 - accuracy: 0.9262 - val_loss: 0.2479 - val_accuracy: 0.8986\n",
      "Epoch 7/8\n",
      "56/56 [==============================] - 105s 2s/step - loss: 0.1645 - accuracy: 0.9357 - val_loss: 0.2355 - val_accuracy: 0.9043\n",
      "Epoch 8/8\n",
      "56/56 [==============================] - 105s 2s/step - loss: 0.1418 - accuracy: 0.9455 - val_loss: 0.2402 - val_accuracy: 0.9072\n"
     ]
    }
   ],
   "source": [
    "history = model_1.fit(X_train, y_train, batch_size = batch_size , validation_data = (X_test,y_test) , epochs = epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353
    },
    "colab_type": "code",
    "id": "LpBtr8mDHSyc",
    "outputId": "0a98558a-4c66-4433-f384-fe86569c455b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-24-ddb552dc6421>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f854a4d8860>"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred = model_1.predict_classes(X_test)\n",
    "cf_matrix = confusion_matrix(y_test,pred)\n",
    "sns.heatmap(cf_matrix, annot=True, fmt='g', xticklabels = ['Fake','Real'] , yticklabels = ['Fake','Real'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "2RsLDXcsG6ZR",
    "outputId": "84e9e5df-b190-48df-9c8e-9d06b6a33d5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score is  0.906928066845864\n",
      "F1 score is 0.9070524530508333\n",
      "Acuracy is  0.9071550255536627\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "auc_score = roc_auc_score(y_test, pred)\n",
    "print(\"AUC score is \", auc_score)\n",
    "\n",
    "F1_score = f1_score(y_test, pred, average='macro')\n",
    "print(\"F1 score is\", F1_score)\n",
    "\n",
    "accuracy_score = accuracy_score(y_test, pred)\n",
    "print(\"Acuracy is \", accuracy_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "juxHt9EBHtME"
   },
   "source": [
    "# **SVM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kCiizJA0Vs2D"
   },
   "outputs": [],
   "source": [
    "cf_matrix = confusion_matrix(y_test,svm_pred)\n",
    "sns.heatmap(cf_matrix, annot=True, fmt='g', xticklabels = ['Fake','Real'] , yticklabels = ['Fake','Real'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "MvmTsxx0kBhj",
    "outputId": "b6014888-dd9f-4611-80d2-c3544dcc603a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score is  0.615212851897777\n",
      "F1 score is 0.61482292536295\n",
      "Acuracy is  0.6155593412833618\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score\n",
    "\n",
    "# Classifier - Algorithm - SVM\n",
    "# fit the training dataset on the classifier\n",
    "SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
    "SVM.fit(X_train,y_train)\n",
    "# predict the labels on validation dataset\n",
    "predictions_SVM = SVM.predict(X_test)\n",
    "\n",
    "\n",
    "auc_score = roc_auc_score(y_test, predictions_SVM)\n",
    "print(\"AUC score is \", auc_score)\n",
    "\n",
    "F1_score = f1_score(y_test, predictions_SVM, average='macro')\n",
    "print(\"F1 score is\", F1_score)\n",
    "\n",
    "accuracy_score = accuracy_score(y_test, predictions_SVM)\n",
    "print(\"Acuracy is \", accuracy_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "faFvh1DVf-xi"
   },
   "source": [
    "# **Naive Bayes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "mLyP6SRggIE6",
    "outputId": "d505298a-0365-4cc6-ccc4-a497793cd602"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score is  0.5764770475335108\n",
      "F1 score is 0.5138666355408052\n",
      "Acuracy is  0.5732538330494037\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score\n",
    "\n",
    "# fit the training dataset on the NB classifier\n",
    "Naive = naive_bayes.MultinomialNB()\n",
    "Naive.fit(X_train, y_train)\n",
    "# predict the labels on validation dataset\n",
    "predictions_NB = Naive.predict(X_test)\n",
    "\n",
    "auc_score = roc_auc_score(y_test, predictions_NB)\n",
    "print(\"AUC score is \", auc_score)\n",
    "\n",
    "F1_score = f1_score(y_test, predictions_NB, average='macro')\n",
    "print(\"F1 score is\", F1_score)\n",
    "\n",
    "accuracy_score = accuracy_score(y_test, predictions_NB)\n",
    "print(\"Acuracy is \", accuracy_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jpoXvLvlmmw5"
   },
   "source": [
    "# **Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "onGCBqCkmrBH",
    "outputId": "4e659821-48c6-4893-eced-15e68686f22c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score is  0.5749126453425093\n",
      "F1 score is 0.5057593237547798\n",
      "Acuracy is  0.5715502555366269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score\n",
    "\n",
    "clf = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "pred_log =  clf.predict(X_test)\n",
    "\n",
    "auc_score = roc_auc_score(y_test, pred_log)\n",
    "print(\"AUC score is \", auc_score)\n",
    "\n",
    "F1_score = f1_score(y_test, pred_log, average='macro')\n",
    "print(\"F1 score is\", F1_score)\n",
    "\n",
    "accuracy_score = accuracy_score(y_test, pred_log)\n",
    "print(\"Acuracy is \", accuracy_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gm8TSiqdn4i6"
   },
   "source": [
    "# **KNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w5YtrsY1n7CM"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "clf = neigh.fit(X_train, y_train)\n",
    "pred_knn =  clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "FtXTNCnko_-e",
    "outputId": "125efb1c-5f12-4764-a5a6-2d971602b584"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score is  0.5937019186581809\n",
      "F1 score is 0.5936872969185022\n",
      "Acuracy is  0.5936967632027257\n"
     ]
    }
   ],
   "source": [
    "auc_score = roc_auc_score(y_test, pred_knn)\n",
    "print(\"AUC score is \", auc_score)\n",
    "\n",
    "F1_score = f1_score(y_test, pred_knn, average='macro')\n",
    "print(\"F1 score is\", F1_score)\n",
    "\n",
    "accuracy_score = accuracy_score(y_test, pred_knn)\n",
    "print(\"Acuracy is \", accuracy_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XbQbm3CmWJ-G"
   },
   "source": [
    "## **DBN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 870
    },
    "colab_type": "code",
    "id": "ekM1nMBfaIFp",
    "outputId": "243d1536-d2ab-477c-b017-aac4d223a623"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+git://github.com/albertbup/deep-belief-network.git\n",
      "  Cloning git://github.com/albertbup/deep-belief-network.git to /tmp/pip-req-build-38i9x6be\n",
      "  Running command git clone -q git://github.com/albertbup/deep-belief-network.git /tmp/pip-req-build-38i9x6be\n",
      "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from deep-belief-network==1.0.3) (1.18.5)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from deep-belief-network==1.0.3) (1.4.1)\n",
      "Requirement already satisfied: scikit-learn>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from deep-belief-network==1.0.3) (0.22.2.post1)\n",
      "Requirement already satisfied: tensorflow>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from deep-belief-network==1.0.3) (2.3.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18.1->deep-belief-network==1.0.3) (0.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.5.0->deep-belief-network==1.0.3) (1.1.0)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.5.0->deep-belief-network==1.0.3) (2.10.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.5.0->deep-belief-network==1.0.3) (1.12.1)\n",
      "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.5.0->deep-belief-network==1.0.3) (1.1.2)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.5.0->deep-belief-network==1.0.3) (0.35.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.5.0->deep-belief-network==1.0.3) (1.15.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.5.0->deep-belief-network==1.0.3) (3.12.4)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.5.0->deep-belief-network==1.0.3) (1.32.0)\n",
      "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.5.0->deep-belief-network==1.0.3) (2.3.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.5.0->deep-belief-network==1.0.3) (0.10.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.5.0->deep-belief-network==1.0.3) (3.3.0)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.5.0->deep-belief-network==1.0.3) (1.6.3)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.5.0->deep-belief-network==1.0.3) (0.2.0)\n",
      "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.5.0->deep-belief-network==1.0.3) (0.3.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.5.0->deep-belief-network==1.0.3) (2.3.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tensorflow>=1.5.0->deep-belief-network==1.0.3) (50.3.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=1.5.0->deep-belief-network==1.0.3) (0.4.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=1.5.0->deep-belief-network==1.0.3) (1.0.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=1.5.0->deep-belief-network==1.0.3) (1.7.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=1.5.0->deep-belief-network==1.0.3) (2.23.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=1.5.0->deep-belief-network==1.0.3) (3.2.2)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=1.5.0->deep-belief-network==1.0.3) (1.17.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow>=1.5.0->deep-belief-network==1.0.3) (1.3.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow>=1.5.0->deep-belief-network==1.0.3) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow>=1.5.0->deep-belief-network==1.0.3) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow>=1.5.0->deep-belief-network==1.0.3) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow>=1.5.0->deep-belief-network==1.0.3) (3.0.4)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow>=1.5.0->deep-belief-network==1.0.3) (1.7.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=1.5.0->deep-belief-network==1.0.3) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=1.5.0->deep-belief-network==1.0.3) (4.1.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=1.5.0->deep-belief-network==1.0.3) (4.6)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow>=1.5.0->deep-belief-network==1.0.3) (3.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow>=1.5.0->deep-belief-network==1.0.3) (3.1.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=1.5.0->deep-belief-network==1.0.3) (0.4.8)\n",
      "Building wheels for collected packages: deep-belief-network\n",
      "  Building wheel for deep-belief-network (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for deep-belief-network: filename=deep_belief_network-1.0.3-cp36-none-any.whl size=13464 sha256=f3d785ae31a65305fdf4bb28fbd33934403b23c4c7671e922a37c12e92eaa453\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-5rqisz0h/wheels/29/6d/3b/6a50cf42a32bdfaa903b17832d60d8d3e5dc4b0fd02ae8acaf\n",
      "Successfully built deep-belief-network\n",
      "Installing collected packages: deep-belief-network\n",
      "Successfully installed deep-belief-network-1.0.3\n"
     ]
    }
   ],
   "source": [
    "% pip install git+git://github.com/albertbup/deep-belief-network.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "WVbi8HzyWPvQ",
    "outputId": "8a030862-6909-4e86-bc7c-31aed0e87c01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 56254806.383125\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 56254820.657007\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 56254443.958099\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 56254085.293391\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 56235574.841113\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 56236024.392956\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 56234460.174612\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 56235458.919449\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 56234296.436590\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 56232033.393680\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 0.000000\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 0.000000\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 0.000000\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 0.000000\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 0.000000\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 0.000000\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 0.000000\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 0.000000\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 0.000000\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 0.000000\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 1 finished \tANN training loss 1.387322\n",
      ">> Epoch 2 finished \tANN training loss 1.387888\n",
      ">> Epoch 3 finished \tANN training loss 1.387748\n",
      ">> Epoch 4 finished \tANN training loss 1.387470\n",
      ">> Epoch 5 finished \tANN training loss 1.387397\n",
      ">> Epoch 6 finished \tANN training loss 1.387422\n",
      ">> Epoch 7 finished \tANN training loss 1.386799\n",
      ">> Epoch 8 finished \tANN training loss 1.387552\n",
      ">> Epoch 9 finished \tANN training loss 1.387288\n",
      ">> Epoch 10 finished \tANN training loss 1.387281\n",
      ">> Epoch 11 finished \tANN training loss 1.386895\n",
      ">> Epoch 12 finished \tANN training loss 1.387353\n",
      ">> Epoch 13 finished \tANN training loss 1.387040\n",
      ">> Epoch 14 finished \tANN training loss 1.387681\n",
      ">> Epoch 15 finished \tANN training loss 1.386857\n",
      ">> Epoch 16 finished \tANN training loss 1.387308\n",
      ">> Epoch 17 finished \tANN training loss 1.387169\n",
      ">> Epoch 18 finished \tANN training loss 1.387210\n",
      ">> Epoch 19 finished \tANN training loss 1.387043\n",
      ">> Epoch 20 finished \tANN training loss 1.387210\n",
      ">> Epoch 21 finished \tANN training loss 1.386941\n",
      ">> Epoch 22 finished \tANN training loss 1.387301\n",
      ">> Epoch 23 finished \tANN training loss 1.387087\n",
      ">> Epoch 24 finished \tANN training loss 1.387484\n",
      ">> Epoch 25 finished \tANN training loss 1.387311\n",
      ">> Epoch 26 finished \tANN training loss 1.387361\n",
      ">> Epoch 27 finished \tANN training loss 1.387137\n",
      ">> Epoch 28 finished \tANN training loss 1.386991\n",
      ">> Epoch 29 finished \tANN training loss 1.387347\n",
      ">> Epoch 30 finished \tANN training loss 1.387176\n",
      ">> Epoch 31 finished \tANN training loss 1.387316\n",
      ">> Epoch 32 finished \tANN training loss 1.387455\n",
      ">> Epoch 33 finished \tANN training loss 1.387073\n",
      ">> Epoch 34 finished \tANN training loss 1.387397\n",
      ">> Epoch 35 finished \tANN training loss 1.387211\n",
      ">> Epoch 36 finished \tANN training loss 1.387144\n",
      ">> Epoch 37 finished \tANN training loss 1.387204\n",
      ">> Epoch 38 finished \tANN training loss 1.387099\n",
      ">> Epoch 39 finished \tANN training loss 1.387696\n",
      ">> Epoch 40 finished \tANN training loss 1.386895\n",
      ">> Epoch 41 finished \tANN training loss 1.387279\n",
      ">> Epoch 42 finished \tANN training loss 1.386822\n",
      ">> Epoch 43 finished \tANN training loss 1.386961\n",
      ">> Epoch 44 finished \tANN training loss 1.386842\n",
      ">> Epoch 45 finished \tANN training loss 1.387502\n",
      ">> Epoch 46 finished \tANN training loss 1.387150\n",
      ">> Epoch 47 finished \tANN training loss 1.387333\n",
      ">> Epoch 48 finished \tANN training loss 1.387509\n",
      ">> Epoch 49 finished \tANN training loss 1.387272\n",
      ">> Epoch 50 finished \tANN training loss 1.386817\n",
      ">> Epoch 51 finished \tANN training loss 1.387290\n",
      ">> Epoch 52 finished \tANN training loss 1.387265\n",
      ">> Epoch 53 finished \tANN training loss 1.386988\n",
      ">> Epoch 54 finished \tANN training loss 1.387373\n",
      ">> Epoch 55 finished \tANN training loss 1.387106\n",
      ">> Epoch 56 finished \tANN training loss 1.387051\n",
      ">> Epoch 57 finished \tANN training loss 1.387305\n",
      ">> Epoch 58 finished \tANN training loss 1.387100\n",
      ">> Epoch 59 finished \tANN training loss 1.387253\n",
      ">> Epoch 60 finished \tANN training loss 1.387171\n",
      ">> Epoch 61 finished \tANN training loss 1.387362\n",
      ">> Epoch 62 finished \tANN training loss 1.387089\n",
      ">> Epoch 63 finished \tANN training loss 1.387486\n",
      ">> Epoch 64 finished \tANN training loss 1.387306\n",
      ">> Epoch 65 finished \tANN training loss 1.387231\n",
      ">> Epoch 66 finished \tANN training loss 1.387155\n",
      ">> Epoch 67 finished \tANN training loss 1.387348\n",
      ">> Epoch 68 finished \tANN training loss 1.387302\n",
      ">> Epoch 69 finished \tANN training loss 1.387184\n",
      ">> Epoch 70 finished \tANN training loss 1.387064\n",
      ">> Epoch 71 finished \tANN training loss 1.386885\n",
      ">> Epoch 72 finished \tANN training loss 1.387033\n",
      ">> Epoch 73 finished \tANN training loss 1.387527\n",
      ">> Epoch 74 finished \tANN training loss 1.387285\n",
      ">> Epoch 75 finished \tANN training loss 1.387173\n",
      ">> Epoch 76 finished \tANN training loss 1.387426\n",
      ">> Epoch 77 finished \tANN training loss 1.387173\n",
      ">> Epoch 78 finished \tANN training loss 1.387321\n",
      ">> Epoch 79 finished \tANN training loss 1.387322\n",
      ">> Epoch 80 finished \tANN training loss 1.386807\n",
      ">> Epoch 81 finished \tANN training loss 1.387256\n",
      ">> Epoch 82 finished \tANN training loss 1.387384\n",
      ">> Epoch 83 finished \tANN training loss 1.387313\n",
      ">> Epoch 84 finished \tANN training loss 1.387204\n",
      ">> Epoch 85 finished \tANN training loss 1.387180\n",
      ">> Epoch 86 finished \tANN training loss 1.387167\n",
      ">> Epoch 87 finished \tANN training loss 1.387388\n",
      ">> Epoch 88 finished \tANN training loss 1.387217\n",
      ">> Epoch 89 finished \tANN training loss 1.387267\n",
      ">> Epoch 90 finished \tANN training loss 1.387281\n",
      ">> Epoch 91 finished \tANN training loss 1.387074\n",
      ">> Epoch 92 finished \tANN training loss 1.386671\n",
      ">> Epoch 93 finished \tANN training loss 1.387373\n",
      ">> Epoch 94 finished \tANN training loss 1.387249\n",
      ">> Epoch 95 finished \tANN training loss 1.387144\n",
      ">> Epoch 96 finished \tANN training loss 1.387396\n",
      ">> Epoch 97 finished \tANN training loss 1.387312\n",
      ">> Epoch 98 finished \tANN training loss 1.387267\n",
      ">> Epoch 99 finished \tANN training loss 1.386991\n",
      ">> Epoch 100 finished \tANN training loss 1.387244\n",
      "[END] Fine tuning step\n",
      "AUC score is  0.5\n",
      "F1 score is 0.3313081450541105\n",
      "Acuracy is  0.4954571266325951\n"
     ]
    }
   ],
   "source": [
    "from dbn import SupervisedDBNClassification\n",
    "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score\n",
    "\n",
    "# Training\n",
    "classifier = SupervisedDBNClassification(hidden_layers_structure=[256, 256], learning_rate_rbm=0.05, learning_rate=0.1, n_epochs_rbm=10, n_iter_backprop=100, batch_size=32, activation_function='relu', dropout_p=0.2)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Test\n",
    "pred_dbn = classifier.predict(X_test)\n",
    "\n",
    "\n",
    "auc_score = roc_auc_score(y_test, pred_dbn)\n",
    "print(\"AUC score is \", auc_score)\n",
    "\n",
    "F1_score = f1_score(y_test, pred_dbn, average='macro')\n",
    "print(\"F1 score is\", F1_score)\n",
    "\n",
    "accuracy_score = accuracy_score(y_test, pred_dbn)\n",
    "print(\"Acuracy is \", accuracy_score)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "fake-real-news-training-8800.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
